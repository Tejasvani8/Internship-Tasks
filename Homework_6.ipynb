{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZOFamTGWvL6"
   },
   "source": [
    "# **Session #6 Homework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVKNxp_YWvL_"
   },
   "source": [
    "### **Loading Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9NdJKA2ZWvMD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__uJk5XNWvMH"
   },
   "source": [
    "### **Getting the data**\n",
    "\n",
    "- using the New York City Airbnb open Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq-m41I1WvMJ"
   },
   "source": [
    "- Use only the following columns:\n",
    "        'neighbourhood_group',\n",
    "        'room_type',\n",
    "        'latitude',\n",
    "        'longitude',\n",
    "        'minimum_nights',\n",
    "        'number_of_reviews','reviews_per_month',\n",
    "        'calculated_host_listings_count',\n",
    "        'availability_365',\n",
    "        'price'\n",
    "- Fill NAs with 0\n",
    "- Apply the log tranform to price\n",
    "- Do train/validation/test split with 60%/20%/20% distribution.\n",
    "- Use the train_test_split function and set the random_state parameter to 1\n",
    "- Use DictVectorizer to turn the dataframe into matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKkdw_v5WvML"
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('AB_NYC_2019.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)\n",
    "df['price'] = np.log1p(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AD7Nu3HyWvMN"
   },
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.price.values\n",
    "y_val = df_val.price.values\n",
    "y_test = df_test.price.values\n",
    "\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "B3zPLfoWWvMP"
   },
   "outputs": [],
   "source": [
    "#use DictVectorizer to turn train and validation into matrices:\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "df_train_dict = df_train.to_dict(orient='records')\n",
    "df_val_dict = df_val.to_dict(orient='records')\n",
    "\n",
    "X_train = dv.fit_transform(df_train_dict)\n",
    "X_val = dv.transform(df_val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Bnh88HJWvMR"
   },
   "source": [
    "### **Question 1**\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable.\n",
    "\n",
    "   - Train a model with max_depth=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iiBFB22dWvMU",
    "outputId": "cfc2a848-bf40-421d-9b82-aa89f6a8d8d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=1,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = DecisionTreeRegressor(max_depth=1)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvH_I8SEWvMX"
   },
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "   - room_type\n",
    "   - neighbourhood_group\n",
    "   - number_of_reviews\n",
    "   - reviews_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6B0G_H18WvMZ",
    "outputId": "32d43333-4f58-4c89-c847-a65b72c7ae47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- room_type=Entire home/apt <= 0.50\n",
      "|   |--- value: [4.29]\n",
      "|--- room_type=Entire home/apt >  0.50\n",
      "|   |--- value: [5.15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(export_text(model1, feature_names=dv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_S-EPbuWvMb"
   },
   "source": [
    "### **Question 2**\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "   - n_estimators=10\n",
    "   - random_state=1\n",
    "   - n_jobs=-1 (optional - to make training faster)\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "   - 0.059\n",
    "   - 0.259\n",
    "   - 0.459\n",
    "   - 0.659\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScSojyzQWvMc",
    "outputId": "18d6f4f4-596a-4524-8436-2af75ed41a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.460888788095762\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "model2.fit(X_train, y_train)\n",
    "pred = model2.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, pred, squared=False)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFr8OBjKWvMe"
   },
   "source": [
    "### **Question 3**\n",
    "\n",
    "Now let's experiment with the n_estimators parameter\n",
    "\n",
    "   - Try different values of this parameter from 10 to 200 with step 10\n",
    "   - Set random_state to 1\n",
    "   - Evaluate the model on the validation dataset\n",
    "\n",
    "After which value of n_estimators does RMSE stop improving?\n",
    "\n",
    "   - 10\n",
    "   - 50\n",
    "   - 70\n",
    "   - 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znucyr2CWvMf",
    "outputId": "545b65a1-3a04-4fee-92d2-6b77ecd8da50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10,    rmse = 0.460888788095762\n",
      "n_estimators = 20,    rmse = 0.44744055425901735\n",
      "n_estimators = 30,    rmse = 0.44440015830200136\n",
      "n_estimators = 40,    rmse = 0.44281711871165336\n",
      "n_estimators = 50,    rmse = 0.44176815762157207\n",
      "n_estimators = 60,    rmse = 0.44125165338475053\n",
      "n_estimators = 70,    rmse = 0.44064455072014125\n",
      "n_estimators = 80,    rmse = 0.440740830263047\n",
      "n_estimators = 90,    rmse = 0.4402749020311618\n",
      "n_estimators = 100,    rmse = 0.4397631903425602\n",
      "n_estimators = 110,    rmse = 0.4393128261208466\n",
      "n_estimators = 120,    rmse = 0.43912990819267467\n",
      "n_estimators = 130,    rmse = 0.43927965755127013\n",
      "n_estimators = 140,    rmse = 0.4391514983746916\n",
      "n_estimators = 150,    rmse = 0.43902892484355854\n",
      "n_estimators = 160,    rmse = 0.4388423640549406\n",
      "n_estimators = 170,    rmse = 0.4387460509023033\n",
      "n_estimators = 180,    rmse = 0.4388528948224223\n",
      "n_estimators = 190,    rmse = 0.43879074353852315\n",
      "n_estimators = 200,    rmse = 0.4387871286025359\n"
     ]
    }
   ],
   "source": [
    "for n in np.linspace(10,200, 20).astype(int):\n",
    "    model3= RandomForestRegressor(n_estimators = n, random_state = 1, n_jobs = -1)\n",
    "    model3.fit(X_train, y_train)\n",
    "    predic = model3.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, predic, squared=False)\n",
    "    print(f\"n_estimators = {n},    rmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKl5e812WvMh"
   },
   "source": [
    "### **Question 4**\n",
    "\n",
    "Let's select the best max_depth:\n",
    "\n",
    "   - Try different values of max_depth: [10, 15, 20, 25]\n",
    "   - For each of these values, try different values of n_estimators from 10 till 200 (with step 10)\n",
    "   - Fix the random seed: random_state=1\n",
    "\n",
    "What's the best max_depth:\n",
    "\n",
    "   - 10\n",
    "   - 15\n",
    "   - 20\n",
    "   - 25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1Nb2fX8uWvMi"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for depth in [10,15,20,25]:\n",
    "    for n in np.linspace(10,200, 20).astype(int):\n",
    "        model4= RandomForestRegressor(n_estimators = n, max_depth = depth, random_state = 1, n_jobs = -1)\n",
    "        model4.fit(X_train, y_train)\n",
    "        preds = model4.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, predic, squared=False)\n",
    "        results.append((depth, n, rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "H0708kX1WvMm"
   },
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results, columns=['max_depth', 'n_estimators', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLM4lu1EehVC",
    "outputId": "62837c1c-bd96-4a0f-dfb5-65487b260a26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.max_depth[df_results.rmse.argmin()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqZwzshKWvMv"
   },
   "source": [
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DRYXgXdWvMx"
   },
   "outputs": [],
   "source": [
    "results1 = []\n",
    "for depth in [10,15,20,25]:\n",
    "    for n in np.linspace(10,200, 20).astype(int):\n",
    "        model4= RandomForestRegressor(n_estimators = n, max_depth = depth, random_state = 2, n_jobs = -1)\n",
    "        model4.fit(X_train, y_train)\n",
    "        preds = model4.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, predic, squared=False)\n",
    "        results1.append((depth, n, rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0nKiOPzWvMy"
   },
   "source": [
    "### **Question 5**\n",
    "\n",
    "We can extract feature importance information from tree-based models.\n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the imporatant features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "  * Train the model with these parametes:\n",
    "     - n_estimators=10,\n",
    "     - max_depth=20,\n",
    "     - random_state=1,\n",
    "     - n_jobs=-1 (optional)\n",
    "  * Get the feature importance information from this model\n",
    "\n",
    "What's the most important feature?\n",
    "\n",
    "   * neighbourhood_group=Manhattan\n",
    "   * room_type=Entire home/apt\n",
    "   * longitude\n",
    "   * latitude\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce7giKivWvMz",
    "outputId": "006e8233-c09f-41b7-f36c-4d3895674913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          0\n",
      "availability_365                   0.076516\n",
      "calculated_host_listings_count     0.030906\n",
      "latitude                           0.152054\n",
      "longitude                          0.153219\n",
      "minimum_nights                     0.053645\n",
      "neighbourhood_group=Bronx          0.000284\n",
      "neighbourhood_group=Brooklyn       0.001166\n",
      "neighbourhood_group=Manhattan      0.034017\n",
      "neighbourhood_group=Queens         0.001153\n",
      "neighbourhood_group=Staten Island  0.000118\n",
      "number_of_reviews                  0.043525\n",
      "reviews_per_month                  0.052438\n",
      "room_type=Entire home/apt          0.391897\n",
      "room_type=Private room             0.004521\n",
      "room_type=Shared room              0.004541\n"
     ]
    }
   ],
   "source": [
    "model5 = RandomForestRegressor(n_estimators = 10, max_depth = 20, random_state = 1, n_jobs = -1)\n",
    "model5.fit(X_train, y_train)\n",
    "imp = model5.feature_importances_\n",
    "\n",
    "modelImp = pd.DataFrame(imp, index = dv.feature_names_)\n",
    "print(modelImp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuzLWSNXWvM0"
   },
   "source": [
    "### **Question 6**\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the eta parameter\n",
    "\n",
    "   - Install XGBoost\n",
    "   - Create DMatrix for train and validation\n",
    "   - Create a watchlist\n",
    "   - Train a model with these parameters for 100 rounds:\n",
    "   \n",
    " xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "\n",
    "Now change eta first to 0.1 and then to 0.01\n",
    "   \n",
    "   \n",
    "What's the best eta?\n",
    "\n",
    "   - 0.3\n",
    "   - 0.1\n",
    "   - 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Zl2KQU3SWvM1"
   },
   "outputs": [],
   "source": [
    "features = dv.get_feature_names()\n",
    "dftrain = xgb.DMatrix(X_train, label = y_train, feature_names = features)\n",
    "dfval = xgb.DMatrix(X_val, label = y_val, feature_names = features)\n",
    "watchlist = [(dftrain, 'train'), (dfval, 'val')]\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eN_5smI3jQOj",
    "outputId": "69419a3c-e534-401e-c0ed-e8c5ffc0fe54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.02752\tval-rmse:3.02415\n",
      "[5]\ttrain-rmse:0.674904\tval-rmse:0.677523\n",
      "[10]\ttrain-rmse:0.439151\tval-rmse:0.449813\n",
      "[15]\ttrain-rmse:0.423031\tval-rmse:0.439126\n",
      "[20]\ttrain-rmse:0.417245\tval-rmse:0.437226\n",
      "[25]\ttrain-rmse:0.412681\tval-rmse:0.436174\n",
      "[30]\ttrain-rmse:0.407563\tval-rmse:0.435124\n",
      "[35]\ttrain-rmse:0.404793\tval-rmse:0.434324\n",
      "[40]\ttrain-rmse:0.401326\tval-rmse:0.434602\n",
      "[45]\ttrain-rmse:0.399043\tval-rmse:0.434132\n",
      "[50]\ttrain-rmse:0.395527\tval-rmse:0.433357\n",
      "[55]\ttrain-rmse:0.391777\tval-rmse:0.433642\n",
      "[60]\ttrain-rmse:0.388646\tval-rmse:0.43327\n",
      "[65]\ttrain-rmse:0.383917\tval-rmse:0.432713\n",
      "[70]\ttrain-rmse:0.380675\tval-rmse:0.432784\n",
      "[75]\ttrain-rmse:0.377159\tval-rmse:0.432945\n",
      "[80]\ttrain-rmse:0.374531\tval-rmse:0.432804\n",
      "[85]\ttrain-rmse:0.37268\tval-rmse:0.4331\n",
      "[90]\ttrain-rmse:0.370312\tval-rmse:0.433563\n",
      "[95]\ttrain-rmse:0.366663\tval-rmse:0.433719\n",
      "[99]\ttrain-rmse:0.36437\tval-rmse:0.434066\n",
      "eta: 0.1\n"
     ]
    }
   ],
   "source": [
    "model6 = xgb.train(xgb_params, dftrain, num_boost_round = 100, verbose_eval = 5, evals=watchlist)\n",
    "y_pred = model6.predict(dfval)\n",
    "rmse1 = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "print(\"eta: 0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Z__PjFWjuQi",
    "outputId": "c039a557-a198-4fe6-ba96-5ab73d6274e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.87217\tval-rmse:3.86889\n",
      "[5]\ttrain-rmse:2.31905\tval-rmse:2.31689\n",
      "[10]\ttrain-rmse:1.41919\tval-rmse:1.41798\n",
      "[15]\ttrain-rmse:0.912897\tval-rmse:0.913599\n",
      "[20]\ttrain-rmse:0.645011\tval-rmse:0.648887\n",
      "[25]\ttrain-rmse:0.517091\tval-rmse:0.52394\n",
      "[30]\ttrain-rmse:0.461519\tval-rmse:0.471089\n",
      "[35]\ttrain-rmse:0.438045\tval-rmse:0.450283\n",
      "[40]\ttrain-rmse:0.427864\tval-rmse:0.44178\n",
      "[45]\ttrain-rmse:0.422597\tval-rmse:0.438206\n",
      "[50]\ttrain-rmse:0.418963\tval-rmse:0.436207\n",
      "[55]\ttrain-rmse:0.416481\tval-rmse:0.435422\n",
      "[60]\ttrain-rmse:0.414688\tval-rmse:0.434822\n",
      "[65]\ttrain-rmse:0.412339\tval-rmse:0.434327\n",
      "[70]\ttrain-rmse:0.410824\tval-rmse:0.433942\n",
      "[75]\ttrain-rmse:0.409584\tval-rmse:0.433725\n",
      "[80]\ttrain-rmse:0.407816\tval-rmse:0.433406\n",
      "[85]\ttrain-rmse:0.406555\tval-rmse:0.433194\n",
      "[90]\ttrain-rmse:0.405447\tval-rmse:0.432963\n",
      "[95]\ttrain-rmse:0.404238\tval-rmse:0.43287\n",
      "[99]\ttrain-rmse:0.404032\tval-rmse:0.432873\n",
      "eta: 0.01\n"
     ]
    }
   ],
   "source": [
    "model7 = xgb.train(xgb_params, dftrain, num_boost_round = 100, verbose_eval = 5, evals=watchlist)\n",
    "y_pred1 = model7.predict(dfval)\n",
    "rmse2 = mean_squared_error(y_val, y_pred1, squared=False)\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.01, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "print(\"eta: 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tN9Q9jiJkD0F",
    "outputId": "3e613ca6-dff4-43b8-fb8f-889db5536b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.25336\tval-rmse:4.2501\n",
      "[5]\ttrain-rmse:4.04779\tval-rmse:4.04454\n",
      "[10]\ttrain-rmse:3.85242\tval-rmse:3.84922\n",
      "[15]\ttrain-rmse:3.66674\tval-rmse:3.66359\n",
      "[20]\ttrain-rmse:3.4903\tval-rmse:3.48718\n",
      "[25]\ttrain-rmse:3.32263\tval-rmse:3.31956\n",
      "[30]\ttrain-rmse:3.16332\tval-rmse:3.16027\n",
      "[35]\ttrain-rmse:3.01196\tval-rmse:3.00898\n",
      "[40]\ttrain-rmse:2.86817\tval-rmse:2.86532\n",
      "[45]\ttrain-rmse:2.73158\tval-rmse:2.72884\n",
      "[50]\ttrain-rmse:2.60185\tval-rmse:2.59924\n",
      "[55]\ttrain-rmse:2.47865\tval-rmse:2.47614\n",
      "[60]\ttrain-rmse:2.36167\tval-rmse:2.35927\n",
      "[65]\ttrain-rmse:2.25061\tval-rmse:2.24836\n",
      "[70]\ttrain-rmse:2.14519\tval-rmse:2.14303\n",
      "[75]\ttrain-rmse:2.04515\tval-rmse:2.04309\n",
      "[80]\ttrain-rmse:1.95021\tval-rmse:1.94831\n",
      "[85]\ttrain-rmse:1.86016\tval-rmse:1.85836\n",
      "[90]\ttrain-rmse:1.77473\tval-rmse:1.77307\n",
      "[95]\ttrain-rmse:1.69373\tval-rmse:1.69216\n",
      "[99]\ttrain-rmse:1.63197\tval-rmse:1.63049\n"
     ]
    }
   ],
   "source": [
    "model8 = xgb.train(xgb_params, dftrain, num_boost_round = 100, verbose_eval = 5, evals=watchlist)\n",
    "y_pred2 = model8.predict(dfval)\n",
    "rmse3 = mean_squared_error(y_val, y_pred2, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkoeYn_1kSLg",
    "outputId": "f318d33e-f5e0-4401-e79e-2e1321602e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final validation rmse for ema = 0.3, rmse = 0.4340655350827198\n",
      "final validation rmse for ema = 0.1, rmse = 0.43287301324031663\n",
      "final validation rmse for ema = 0.01, rmse = 1.6304939442439164\n"
     ]
    }
   ],
   "source": [
    "print(f\"final validation rmse for ema = 0.3, rmse = {rmse1}\")\n",
    "print(f\"final validation rmse for ema = 0.1, rmse = {rmse2}\")\n",
    "print(f\"final validation rmse for ema = 0.01, rmse = {rmse3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NteBmS3WvM2"
   },
   "source": [
    "#                                                 **DONE**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Homework-#6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
